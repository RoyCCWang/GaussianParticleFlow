# test exact Gaussian flow.


using Distributed

@everywhere import HCubature
@everywhere import Utilities
@everywhere import Printf
@everywhere import PyPlot
@everywhere import Random

@everywhere using LinearAlgebra
@everywhere import Interpolations

@everywhere using FFTW

@everywhere import Statistics

@everywhere import Distributions

@everywhere import Calculus

@everywhere import ForwardDiff
@everywhere import StatsFuns

using Test
using BenchmarkTools

import VisualizationTools

#@everywhere import Seaborn
@everywhere include("../src/misc/declarations.jl")

@everywhere include("../src/SDE/Brownian.jl")
@everywhere include("../src/flows/approx_flow.jl")
@everywhere include("../tests/routines/sde.jl")
@everywhere include("../src/flows/moments.jl")
@everywhere include("../src/flows/derivatives.jl")
@everywhere include("../src/misc/utilities.jl")
@everywhere include("../src/misc/utilities2.jl")

@everywhere include("../tests/routines/simulation_tools.jl")
@everywhere include("../src/flows/exact_flow.jl")

@everywhere include("../src/importance_sampler/IS_engine.jl")
@everywhere include("../src/diagnostics/functionals.jl")


@everywhere include("../src/flows/traverse_with_weights.jl")
@everywhere include("../src/flows/traverse_no_weights.jl")


### adaptive kernel.
@everywhere include("./adaptive_kernel/scalar.jl")
@everywhere include("./adaptive_kernel/traverse.jl")
@everywhere include("./adaptive_kernel/L1_moments.jl")

## TODO I am here. go through routines to ensure as fast as possible
#    implementation of GFlow, with options to cache Brownian motion, or
#    draw on demand.

# how can transport help with likelihoods?

PyPlot.close("all")
fig_num = 1

Random.seed!(25)
#Random.seed!(435)
#Random.seed!(244432)


N_batches = 16



#
max_integral_evals = typemax(Int) #1000000
initial_div = 1000



D_x = 6
Î¸_a = rand()

A_Ï• = randn(D_x, D_x)
Ï• = xx->sinc(dot(xx,A_Ï•*xx))
dÏ• = Ï•
d2Ï• = Ï•

# hardcode set up for L = 1, for now.
ÏƒÂ² = rand()
ÏƒÂ²_vec = [ ÏƒÂ² ]
R = ones(Float64, 1, 1)
R[1] = ÏƒÂ²

P_0 = diagm( ÏƒÂ² .* ones(D_x) )
m_0 = randn(D_x) # this is z_input.
z_input = m_0

Ïˆ = xx->[ Ï•(xx) ]
y = randn(1)

prior_dist = Distributions.MvNormal(m_0, P_0)

ln_prior_pdf_func = xx->Distributions.logpdf(prior_dist, xx)
ln_likelihood_func = xx->evallnMVNlikelihood(xx, y, m_0, P_0, Ïˆ, R)



###### verify moment expressions. pakage into test script when done.
L = 1

x0 = randn(D_x)
Î»0 = rand()
Î»1 = Î»0 + rand()




inv_P0 = diagm(1/ÏƒÂ² * ones(Float64, D_x))
inv_R = diagm(1/ÏƒÂ² * ones(Float64, L))

getPquantities_Bunch = (xx,Î»Î»)->computePquantitiesBunch(xx, Î»Î», Ïˆ, inv_P0, inv_R)

getPquantities_mine = (xx,Î»Î»)->computePquantitiesL1(xx, Î»Î», Ïˆ, ÏƒÂ²)

B, inv_B = getPquantities_Bunch(x0, Î»0)
C, inv_C = getPquantities_mine(x0, Î»0)

println("verify my P update.")
println("l-2 discrepancy of P: mine vs. Bunch is ", norm(B-C))
println("l-2 discrepancy of inv(P): mine vs. Bunch is ", norm(inv_B-inv_C))
println()



# # verify sqrtm formula.
# u = randn(D_x)
# K = rand()* 5.3
#
# Q = LinearAlgebra.I + K .* u*u'
#
# x = ( sqrt(1+dot(u,u)*K)-1 )/dot(u,u)
# sqrt_Q = LinearAlgebra.I + x .* u*u'
# println("verify sqrt formula.")
# println("l-2 discrepancy of sqrt(Q) vs. Q is ", norm(sqrt_Q-sqrt(Q)))
# println()



### verify formula for d(uáµ€u).

function evalduáµ€u(Ïˆ, x::Vector{T})::Vector{T} where T
    D = length(x)

    dÏˆ_x = ForwardDiff.gradient(Ïˆ, x)
    d2Ïˆ_x = ForwardDiff.hessian(Ïˆ, x)

    return collect( sum( 2*dÏˆ_x[i]*d2Ïˆ_x[i,j] for i = 1:D ) for j = 1:D )
end

function evaluáµ€u(Ïˆ, x::Vector{T})::T where T

    u = ForwardDiff.gradient(Ïˆ, x)

    return dot(u,u)
end

Ïˆ_scalar = xx->Ïˆ(xx)[1]

f = xx->evaluáµ€u(Ïˆ_scalar, xx)
df_AD = xx->ForwardDiff.gradient(f, xx)

df_AN = xx->evalduáµ€u(Ïˆ_scalar, xx)

## comment out for speed.
# A = df_AD(x0)
# B = df_AN(x0)
#
# println("verify d(uáµ€u) formula.")
# println("d(uáµ€u), L = 1: l-2 discrepancy between AN and AD is ", norm(A-B))
# println()



# skip to speed up.
# ### verify dğº formula.
# getğº_Bunch = xx->computeğºBunch(xx, Î»0, Î»1, Ïˆ, inv_P0, inv_R)
# getğºquantities_mine = xx->computeğº(xx, Î»0, Î»1, Ïˆ_scalar, ÏƒÂ²)
#
# G_Bunch = getğº_Bunch(x0)
# dG_Bunch = computegradientformatrixfunctionND(x0, getğº_Bunch, D_x, D_x)
#
# G_mine, dG_mine = getğºquantities_mine(x0)
#
# println("verify ğº formula.")
# println("ğº, L = 1: l-2 discrepancy between my formula and Bunch is  ", norm(G_Bunch-G_mine))
# println("dğº, L = 1: l-2 discrepancy between my formula and Bunch is ", norm(dG_Bunch-dG_mine))
# println()


### Verify dm.
import FiniteDiff


### next, devise fast expression for weight Jacobian and state updates.

### consider how remedy negative determinant. look at logabsdet.
### consider how to remedy logabsdet = -Inf, i.e. determinant at x0 is zero,
#       i.e. state update is not invertible there. add noise?

# intermediate tests, leading up to dğ‘š.
y_hat_func = xx->computeyhatL1(xx, Ïˆ, y)
dy_hat_AD = xx->ForwardDiff.jacobian(y_hat_func, xx)

d2Ïˆ_scalar = xx->ForwardDiff.hessian(Ïˆ_scalar, xx)

dy_hat_x0_mine = collect( dot( d2Ïˆ_scalar(x0)[:,j], x0) for j = 1:D_x )
dy_hat_x0_AD = vec(dy_hat_AD(x0))

println("dy_hat discrepancy: mine vs. AD is ", norm(dy_hat_x0_mine-dy_hat_x0_AD))
println()


y_scalar = y[1]
Îº_func = xx->computeÎº(xx, z_input, Î»0, Ïˆ_scalar, ÏƒÂ², y_scalar)
Îº_x0 = Îº_func(x0)

dÎº_AD = xx->ForwardDiff.gradient(Îº_func, xx)
dÎº_AD_x0 = dÎº_AD(x0)

dÎº = xx->computedÎº(xx, z_input, Î»0, Ïˆ_scalar, ÏƒÂ², y_scalar)
dÎº_x0 = dÎº(x0)

println("dÎº discrepancy: mine vs. AD is ", norm(dÎº_x0-dÎº_AD_x0))
println()
#@assert 1==2



#####
getğ‘š_Bunch = xx->computeğ‘šBunch(xx, Î»0, Ïˆ, z_input, inv_P0, inv_R, y)

getdğ‘š_Bunch = xx->computedğ‘šBunch(xx, Î»0, Ïˆ, z_input, inv_P0, inv_R, y)

ğ‘š_Bunch = getğ‘š_Bunch(x0)

dğ‘š_Bunch_mat = ForwardDiff.jacobian(xx->getğ‘š_Bunch(xx), x0)
dğ‘š_Bunch = collect( vec(dğ‘š_Bunch_mat[j,:]) for j = 1:D_x )

#ğ‘š_mine, dğ‘š_mine, dk_mine = getğ‘šquantities_mine(x0)

ğ‘š_func_mine = xx->computeğ‘š(xx, z_input, Î»0, Ïˆ_scalar, ÏƒÂ², y_scalar)
dğ‘š_AD = xx->ForwardDiff.jacobian(ğ‘š_func_mine, xx)

dğ‘š_mine = xx->computedğ‘š(xx, z_input, Î»0, Ïˆ_scalar, ÏƒÂ², y_scalar)

dğ‘š_mine_x0 = dğ‘š_mine(x0)
dğ‘š_mine_x0_mat = convertnestedvector(dğ‘š_mine_x0)
#dğ‘š_mine_x0_mat = dğ‘š_mine_x0_mat'

dğ‘š_AD_x0 = dğ‘š_AD(x0)

println("dğ‘š: l-2 discrepancy between AN and AD is ", norm(dğ‘š_AD_x0-dğ‘š_mine_x0_mat))

@assert 1==2

println("verify ğ‘š formula.")
println("ğ‘š, L = 1: l-2 discrepancy between my formula and Bunch is  ", norm(ğ‘š_Bunch-ğ‘š_mine))
println("dğ‘š, L = 1: l-2 discrepancy between my formula and Bunch is ", norm(dğ‘š_Bunch-dğ‘š_mine))
println()


@assert 1==222

### flow.

## set up SDE.
#N_discretizations = 1000
N_discretizations = 1000
Î³ = 0.0
#N_particles = 20

# x = rand(prior_dist)
#
# println("old: traversesdepathapproxflow")
# Random.seed!(25)
# problem_params,
#     problem_methods,
#     GF_buffers,
#     GF_config = setupGFquantities( Î³,
#                             m_0,
#                             P_0,
#                             R,
#                             y,
#                             Ïˆ,
#                             âˆ‚Ïˆ,
#                             âˆ‚2Ïˆ,
#                             ln_prior_pdf_func,
#                             ln_likelihood_func)
#
# Î»_array, BÎ»_array = drawBrownianmotiontrajectorieswithoutstart(N_discretizations, D_x);
# #
# #
# @time ğ‘¥, ğ‘¤ = traversesdepathapproxflow(   x,
#                                  Î»_array,
#                                  BÎ»_array,
#                                  problem_params,
#                                  problem_methods,
#                                  GF_buffers,
#                                  GF_config)

#
println("new: traversesdepathapproxflow")
Random.seed!(25)

L = 1
z = m_0

# function evaladaptiveGaussiankernel(x::Vector{T2},
#                                     z::Vector{T},
#                                     a::T,
#                                     Ï•,
#                                     Ï•_z::T = Ï•(z))::T2 where {T,T2}
#     #
#     @assert length(x) == length(z)
#
#     term1::T2 = zero(T2)
#     for d = 1:length(x)
#         term1 += (x[d]-z[d])^2
#     end
#
#     term2::T2 = (Ï•(x)-Ï•(z))^2
#
#     out = exp(-a*(term1+term2))
#
#     return out
# end

# I am here.


problem_params,
    problem_methods,
    GF_buffers,
    GF_config = setupGFAKscalar( Î³,
                            z,
                            Î¸_a,
                            Ï•,
                            dÏ•,
                            d2Ï•,
                            L)
@assert 1333==3
@time ğ‘¥2, ğ‘¤2 = traverseGFAK(  x,
                                Î»_array,
                                problem_params,
                                problem_methods,
                                GF_buffers,
                                GF_config)
#
## compare.
discrepancy_x = norm(ğ‘¥2-ğ‘¥)
discrepancy_w = norm(ğ‘¤2-ğ‘¤)

println("discrepancy_x = ", discrepancy_x)
println("discrepancy_w = ", discrepancy_w)
println()
