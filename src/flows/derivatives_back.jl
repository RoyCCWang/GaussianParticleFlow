####### for weight integration.

# equation 27.
function computelnabsdetJofstateupdate(  位_a::T,
                                        位_b::T,
                                        problem_params,
                                         problem_methods,
                                         GF_buffers::GaussianFlowSimpleBuffersType{T},
                                         GF_config,
                                        x::Vector{T},
                                        系_a::Vector{T},
                                        系_b::Vector{T}) where T <: Real
    # parse.
     = GF_buffers.
    _a = GF_buffers._a
    _b = GF_buffers._b
    _a = GF_buffers._a
    _b = GF_buffers._b
     = GF_buffers.

    R = problem_params.R
    纬 = GF_config.纬

    # set up.
    t_x::Vector{Matrix{T}} = gettfunc(x_a)

    D_x = length(t_x)
    位 = 位_b - 位_a
    系 = 系_b - 系_a
    x_minus__a = x - _a
    _b_inv_a = _b*inv(_a)

    # # prepare derivatives.
    # _a_x = computewrtx(t_x, 位_a, R, , _a, _a, x, )
    # _b_x = computewrtx(t_x, 位_b, R, , _b, _b, x, )
    #
    # #_a_x = computewrtx(t_x, 位_a, R, , _a)
    # _b_x = computewrtx(t_x, 位_b, R, , _b)
    # _b_inv_a_x = computebinvawrtx(t_x, 位_a, 位_b, R, , _a, _b)
    #
    # #_a_sqrt_x = computemsqrtderivatives(_a, _a_x)
    # _b_sqrt_x = computemsqrtderivatives(_b, _b_x)
    # _b_inv_a_sqrt_x = computemsqrtderivatives(_b_inv_a, _b_inv_a_x)

    # other recurring factors.
    exp_half_factor = exp(-0.5*纬*位)
    factor12 = real.(LinearAlgebra.sqrt(_b*inv(_a)))

    exp_factor = sqrt( (one(T) - exp(-纬*位))/位 )

    # first term.
    J = _b_x + exp_half_factor*factor12*(LinearAlgebra.I - _a_x)

    # the other terms.
    for i = 1:D_x
        for j = 1:D_x

            term2 = sum( _b_sqrt_x[j][i,k]*系[k] for k = 1:D_x )

            tmp = sum( _b_inv_a_sqrt_x[j][i,k]*x_minus__a[k] for k = 1:D_x )
            term3 = exp_half_factor*tmp

            J[i,j] = J[i,j] + term2 + term3

        end
    end

    return logabsdet(J)[1]
end

# equation 28.
function computewrtx(t_x::Vector{Matrix{T}},
                        位::T,
                        R::Matrix{T},
                        ::Matrix{T},
                        ::Matrix{T},
                        ::Vector{T},
                        x::Vector{T},
                        ::Vector{T})::Matrix{T} where T <: Real

    #
    D_x = size(,2)
    @assert length(x) == D_x == length(t_x)

    _x = Matrix{T}(undef,D_x,D_x)
    for j = 1:D_x
        t_xj = t_x[j]
        _xj = t_xj'

        term1 = t_xj*(R\( - *))
        term2 = '*(R\(_xj*(x - )))

        _x[:,j] = 位**(term1 + term2)
    end

    return _x
end

# equation 28.
function computewrtx(   t_x::Vector{Matrix{T}},
                            位::T,
                            R::Matrix{T},
                            ::Matrix{T},
                            ::Matrix{T})::Vector{Matrix{T}} where T <: Real

    #
    D_x = size(,2)
    @assert length(t_x) == D_x

    _x = Vector{Matrix{T}}(undef,D_x)
    for j = 1:D_x
        t_xj = t_x[j]
        _xj = t_xj'

        _x[j] = -位**( t_xj*(R\) + '*(R\_xj) )*
    end

    return _x
end

# equation 28.
function computebinvawrtx(t_x::Vector{Matrix{T}},
                            位_a::T,
                            位_b::T,
                            R::Matrix{T},
                            ::Matrix{T},
                            _a::Matrix{T},
                            _b)::Vector{Matrix{T}} where T <: Real

    #
    D_x = size(,2)
    @assert length(t_x) == D_x

    binva_x = Vector{Matrix{T}}(undef,D_x)
    for j = 1:D_x
        t_xj = t_x[j]
        _xj = t_xj'

        factor1 = (位_a*LinearAlgebra.I - 位_b*_b*inv(_a))
        binva_x[j] = _b*( t_xj*(R\) + '*(R\_xj) )*factor1
    end

    return binva_x
end
